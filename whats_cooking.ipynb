{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "Este proyecto tiene como objetivo desarrollar un modelo de deep learning capaz de clasificar recetas en categorías basadas en sus ingredientes. La idea es facilitar la búsqueda de recetas al predecir el tipo de cocina al que pertenece una lista de ingredientes.\n",
    "\n",
    "El proyecto abordará esta tarea implementando un modelo que procese ingredientes, los interprete en el contexto de distintas cocinas, y aprenda a clasificar la receta en categorías como \"italiana\", \"mexicana\" o \"asiática\". Para lograrlo, primero se recolectará un dataset de recetas, se preprocesarán los datos para convertir los ingredientes en vectores utilizando un embedding, y se entrenará un modelo de Red Neuronal Recurrente (RNN) para clasificar las recetas.\n",
    "\n",
    "---\n",
    "\n",
    "# Exploración, explicación y limpieza de datos\n",
    "## Explicación de los datos\n",
    "Para comenzar, se encontró un dataset en Kaggle que contiene recetas de distintas cocinas. El dataset se llama \"What's Cooking?\" y se divide en tres archivos. Primeramente, el archivo `train.json` contiene las recetas de entrenamiento, cada una con una lista de ingredientes y una etiqueta que indica el tipo de cocina. Por otro lado, el archivo `test.json` contiene recetas de prueba, pero sin las etiquetas de cocina, ya que este kaggle está diseñado para competencias. \n",
    "\n",
    "Por el motivo anterior, se decidió dividir el archivo `train.json` en dos partes: una para entrenamiento y otra de testeo. De esta manera, se podrá evaluar el modelo con datos que no ha visto antes.\n",
    "\n",
    "El dataset se creo en el 2015 por el mismo Kaggle y aquí está el [link](https://www.kaggle.com/competitions/whats-cooking/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento:  (31819, 3)\n",
      "Prueba:  (7955, 3)\n",
      "          id   cuisine                                        ingredients\n",
      "23436  46505   mexican  [shredded cheddar cheese, chicken meat, choppe...\n",
      "7901   16624    indian  [fresh cilantro, purple onion, ground coriande...\n",
      "25718   3415  filipino  [sugar, garlic, onions, vinegar, green chilies...\n",
      "16909   4589  moroccan  [raw pistachios, purple onion, couscous, dried...\n",
      "34830   7766   mexican  [tomatoes, pepper, salsa, sliced green onions,...\n",
      "          id  cuisine                                        ingredients\n",
      "21513   7958  chinese  [pork, cooking oil, bamboo shoots, chinese ric...\n",
      "1796   36179  spanish  [hog casings, hungarian paprika, ancho powder,...\n",
      "21861   8331    greek  [lamb stock, lemon, lamb shoulder, onions, gro...\n",
      "26571  41097   indian  [green peas, cinnamon sticks, clove, chopped o...\n",
      "28720   2007  italian  [vegetable oil spray, cumin seed, grated parme...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cargar los archivos JSON de entrenamiento y prueba\n",
    "with open('whats-cooking/train.json') as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['cuisine'] = df['cuisine'].astype('category')\n",
    "\n",
    "# Dividir el conjunto en entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Entrenamiento: ', train_df.shape)\n",
    "print('Prueba: ', test_df.shape)\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de los datos\n",
    "\n",
    "Ya revisando concretamente cada uno de los archivos, se puede observar que el df `train_df` contiene 31819 recetas de entrenamiento, cada una con los siguientes campos:\n",
    "\n",
    "|   # | Column      | Non-Null Count | Dtype    |\n",
    "|-----|-------------|----------------|----------|\n",
    "| 0   | id          | 31819 non-null | int64    |\n",
    "| 1   | cuisine     | 31819 non-null | category |\n",
    "| 2   | ingredients | 31819 non-null | object   |\n",
    "\n",
    "Por otro lado, el df `test_df` contiene 7955 recetas de prueba, cada una con los siguientes campos:\n",
    "\n",
    "|   # | Column      | Non-Null Count | Dtype    |\n",
    "|-----|-------------|----------------|----------|\n",
    "| 0   | id          | 7955 non-null | int64    |\n",
    "| 1   | cuisine     | 7955 non-null | category |\n",
    "| 2   | ingredients | 7955 non-null | object   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de ingredientes por receta en el conjunto de entrenamiento: 10.77\n",
      "Número de cocinas en el conjunto de entrenamiento: 20\n",
      "cuisine\n",
      "italian         6271\n",
      "mexican         5102\n",
      "southern_us     3472\n",
      "indian          2401\n",
      "chinese         2163\n",
      "french          2096\n",
      "thai            1224\n",
      "cajun_creole    1218\n",
      "japanese        1139\n",
      "greek            926\n",
      "spanish          807\n",
      "vietnamese       681\n",
      "korean           664\n",
      "moroccan         655\n",
      "british          647\n",
      "filipino         619\n",
      "irish            516\n",
      "jamaican         435\n",
      "russian          400\n",
      "brazilian        383\n",
      "Name: count, dtype: int64\n",
      "Número de ingredientes únicos: 6303\n",
      "Recipes with the most ingredients:\n",
      "Recipe 15289: 65 ingredients\n",
      "Recipe 26103: 52 ingredients\n",
      "Recipe 10513: 49 ingredients\n",
      "Recipe 22906: 49 ingredients\n",
      "Recipe 31250: 43 ingredients\n",
      "Recipe 345: 40 ingredients\n",
      "Recipe 6449: 40 ingredients\n",
      "Recipe 3359: 40 ingredients\n",
      "Recipe 10379: 38 ingredients\n",
      "Recipe 294: 38 ingredients\n",
      "Recipe 28480: 36 ingredients\n",
      "Recipe 6139: 36 ingredients\n",
      "Recipe 37941: 35 ingredients\n",
      "Recipe 13940: 35 ingredients\n",
      "Recipe 33822: 35 ingredients\n",
      "Recipe 6380: 34 ingredients\n",
      "Recipe 20080: 34 ingredients\n",
      "Recipe 19749: 33 ingredients\n",
      "Recipe 21896: 33 ingredients\n",
      "Recipe 25223: 33 ingredients\n"
     ]
    }
   ],
   "source": [
    "# Calcular la cantidad de ingredientes por receta en el conjunto de entrenamiento\n",
    "train_df['num_ingredients'] = train_df['ingredients'].apply(len)\n",
    "\n",
    "# Calcular el promedio de ingredientes por receta\n",
    "avg_num_ingredients = train_df['num_ingredients'].mean()\n",
    "print(f\"Promedio de ingredientes por receta en el conjunto de entrenamiento: {avg_num_ingredients:.2f}\")\n",
    "\n",
    "# Calcular la cantidad de recetas por tipo de cocina\n",
    "cuisine_counts = train_df['cuisine'].value_counts()\n",
    "print(f\"Número de cocinas en el conjunto de entrenamiento: {cuisine_counts.shape[0]}\")\n",
    "print(cuisine_counts)\n",
    "\n",
    "\n",
    "# Calcular la cantidad de ingredientes únicos\n",
    "unique_ingredients = set()\n",
    "for ingredients in train_df['ingredients']:\n",
    "    unique_ingredients.update(ingredients)\n",
    "num_unique_ingredients = len(unique_ingredients)\n",
    "print(f\"Número de ingredientes únicos: {num_unique_ingredients}\")\n",
    "\n",
    "# Get the 5 recipes with the most ingredients\n",
    "recipes_most_ingredients = train_df.loc[num_ingredients.nlargest(20).index]\n",
    "print(\"Recipes with the most ingredients:\")\n",
    "\n",
    "# Print the quantity of ingredients for each recipe\n",
    "for i, recipe in recipes_most_ingredients.iterrows():\n",
    "    print(f\"Recipe {i}: {len(recipe['ingredients'])} ingredients\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de los datos\n",
    "\n",
    "Haciendo una exploración de los datos, se puede observar que no hay valores nulos en los archivos `train.json` y `test.json`. Además, las columnas que contienen son muy directas para lo que se quiere realizar. Por lo tanto, no se realizará ninguna limpieza de datos.\n",
    "\n",
    "Además, se identificaron 6703 ingredientes únicos en el dataset y 20 tipos de cocina distintos. Por otra parte, únicamente se encontraron 6303 ingredientes únicos en el dataset de entrenamiento, por lo que al momento de tokenizar los ingredientes, se deberá tener en cuenta que existen ingredientes en el dataset de prueba que no están presentes en el dataset de entrenamiento.\n",
    "\n",
    "Otros datos relevantes es que, con diferencia, la cocina más común en el dataset es la italiana, seguida por la mexicana y la del sur de los Estados Unidos. Por otro lado, la cocina más rara en el dataset es la de Reino Unido.\n",
    "\n",
    "## Transformación de los datos\n",
    "\n",
    "Ahora que se ha explorado y limpiado los datos, se procederá a transformar los ingredientes en vectores utilizando un embedding. Para ello, primeramente se tokenizarán los ingredientes. Esto se hará utilizando la clase `Tokenizer` de Keras, la cual se encargará de convertir los ingredientes en secuencias de números enteros.\n",
    "\n",
    "---\n",
    "\n",
    "# Implementación del modelo\n",
    "\n",
    "## Planteamiento del modelo\n",
    "\n",
    "Ahora si, el plan que se tiene para realizar esta compleja tarea es realizar un modelo de aprendizaje profundo que se basa en embeddings de ingredientes generados mediante FastText. Esto se realiza con el objetivo de alimentar con estos embeddings a una red neuronal recurrente (RNN) para realizar la clasificación.\n",
    "\n",
    "Importante recalcar que conforme se avance con el desarrollo del proyecto, se irá justificando cada decisión tomada y se explicará el proceso de implementación de cada componente del modelo. \n",
    "\n",
    "Finalmente, se realizarán pruebas posteriores con diferentes configuraciones de hiperparámetros y cambios en la arquitectura del modelo para buscar optimizar su rendimiento, de manera que se pueda obtener un modelo que sea capaz de clasificar recetas con la más alta precisión.\n",
    "\n",
    "## Estructura del Proyecto\n",
    "\n",
    "1. **Generación de Embeddings con FastText**: Creamos embeddings para los ingredientes de las recetas utilizando FastText. Este método permite capturar relaciones semánticas y contextuales entre los ingredientes, ayudando al modelo a entender similitudes y patrones entre diferentes combinaciones de ingredientes.\n",
    "   \n",
    "2. **Implementación de la RNN**: Utilizamos los embeddings generados como entrada a una red neuronal recurrente. La RNN es adecuada para este problema debido a su habilidad para manejar secuencias de longitud variable, lo cual es común en listas de ingredientes.\n",
    "\n",
    "3. **Entrenamiento y Evaluación**: Entrenamos el modelo en un conjunto de datos de entrenamiento y lo evaluamos en un conjunto de prueba, con métricas de precisión y análisis del rendimiento.\n",
    "\n",
    "A continuación, presentamos los detalles de la implementación de FastText, incluyendo las decisiones tomadas para optimizar los parámetros de este modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'onion' and 'purple onion': 0.7392172813415527\n",
      "Most similar ingredients to 'tomato': [('tomatoes', 0.9098507761955261), ('sauce tomato', 0.8709294199943542), ('organic tomato', 0.85999596118927), ('yellow tomato', 0.8564296364784241), ('tomato chutney', 0.8525497317314148)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "# Prepare data for FastText: each recipe's ingredients become a \"sentence\"\n",
    "corpus = [list(map(str.lower, ingredients)) for ingredients in train_df['ingredients']]\n",
    "\n",
    "# Train a FastText model\n",
    "fasttext_model = FastText(\n",
    "    sentences=corpus,\n",
    "    vector_size=100,  # Dimension of the embeddings\n",
    "    window=3,         # Context window size\n",
    "    min_count=2,      # Ignores words with total frequency lower than this\n",
    "    sg=1,             # 1 for skip-gram; 0 for CBOW\n",
    "    epochs=10         # Number of training epochs\n",
    ")\n",
    "\n",
    "# Save model to disk (optional)\n",
    "fasttext_model.save(\"ft_100_3_2_1_10.model\")\n",
    "\n",
    "# Example: Check similarity between specific ingredients\n",
    "similarity = fasttext_model.wv.similarity(\"onion\", \"purple onion\")\n",
    "print(f\"Similarity between 'onion' and 'purple onion': {similarity}\")\n",
    "\n",
    "# Example: Find most similar words to \"tomato\"\n",
    "similar_words = fasttext_model.wv.most_similar(\"tomato\", topn=5)\n",
    "print(\"Most similar ingredients to 'tomato':\", similar_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de Embeddings de Ingredientes con FastText\n",
    "\n",
    "Como se mencionó anteriormente, se realizó utilizando FastText para generar embeddings de los ingredientes. FastText es una biblioteca de código abierto desarrollada por Facebook que permite entrenar modelos de vectores de palabras y generar embeddings para palabras y frases. En este caso, utilizamos FastText para generar embeddings de los ingredientes de las recetas, lo cual nos permitirá representar los ingredientes en un espacio vectorial y alimentarlos a la red neuronal recurrente.\n",
    "\n",
    "Aquí la razón por la que se utilizaron los parámetros de FastText:\n",
    "\n",
    "- **`vector_size=100`**: Elegimos una dimensión de 100 para los embeddings, buscando un equilibrio entre precisión y eficiencia. Una dimensión mayor podría capturar más matices semánticos, pero también requiere mayor memoria y tiempo de cómputo.\n",
    "\n",
    "- **`window=3`**: Este parámetro define el tamaño de la ventana de contexto alrededor de cada palabra. Optamos por 3 considerando que los ingredientes de un platillo suelen estar relacionados en términos cercanos (es decir, es probable que los ingredientes relacionados aparezcan juntos).\n",
    "\n",
    "- **`min_count=2`**: Esto indica que FastText ignorará palabras con una frecuencia menor a 2. Este umbral permite reducir el ruido de ingredientes poco comunes, que no aportan gran valor al aprendizaje del modelo.\n",
    "\n",
    "- **`sg=1`**: Al establecer `sg=1`, seleccionamos el modelo Skip-Gram en lugar del Continuous Bag of Words (CBOW). Skip-Gram es particularmente útil en este caso porque ayuda a capturar relaciones de palabras infrecuentes, lo cual es común en los ingredientes de recetas.\n",
    "\n",
    "- **`epochs=10`**: Finalmente, usamos 10 épocas para entrenar el modelo. Este número de iteraciones asegura que el modelo tiene suficientes oportunidades para aprender relaciones complejas entre ingredientes sin sobreajustarse al conjunto de datos.\n",
    "\n",
    "Estos parámetros de inicio se consideran adecuados para el problema de clasificación de recetas, se podrían ajustar pero al ser complicado evaluar el rendimiento de los embeddings, se decidió dejarlos así, será mejor dedicar esfuerzos en la optimización de la red neuronal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define la longitud máxima de la secuencia, para que todas las recetas tengan el mismo tamaño\n",
    "max_len = 14  # Ajusta según la longitud promedio de ingredientes en tus recetas\n",
    "\n",
    "# Cargar el modelo FastText\n",
    "fasttext_model = FastText.load(\"ft_100_3_2_1_10.model\")\n",
    "\n",
    "def get_embedding_sequence(recipe, model, max_len=max_len):\n",
    "    \"\"\"\n",
    "    Convierte una lista de ingredientes en una secuencia de embeddings.\n",
    "    Rellena con vectores de ceros si la receta tiene menos de `max_len` ingredientes.\n",
    "    \"\"\"\n",
    "    # Obtener embeddings de cada ingrediente si existe en el modelo\n",
    "    embeddings = [model.wv[ingredient] for ingredient in recipe if ingredient in model.wv]\n",
    "    # Recortar o completar con ceros según el tamaño `max_len`\n",
    "    if len(embeddings) < max_len:\n",
    "        embeddings.extend([np.zeros(model.vector_size)] * (max_len - len(embeddings)))\n",
    "    else:\n",
    "        embeddings = embeddings[:max_len]\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Generar secuencias de embeddings para todas las recetas en el conjunto de entrenamiento\n",
    "X_train = np.array([get_embedding_sequence(recipe, fasttext_model) for recipe in train_df['ingredients']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversión de Ingredientes a Secuencias de Embeddings con FastText\n",
    "\n",
    "Como se mencionó anteriormente, después de generar los embeddings de los ingredientes utilizando FastText, el siguiente paso es convertir cada receta en una secuencia de estos embeddings para alimentar al modelo de deep learning. Este proceso garantiza que todas las recetas tengan una representación consistente y adecuada para su procesamiento.\n",
    "\n",
    "- **Definición de Longitud Máxima (`max_len=14`)**: Se define `max_len` como 14, indicando que cada receta debe estar representada por una secuencia de 14 vectores de embeddings. Si una receta tiene menos de 14 ingredientes, la secuencia se completará con vectores de ceros. Este valor se ajusta según la longitud promedio de ingredientes en las recetas.\n",
    "\n",
    "- **Carga del Modelo FastText**: Se carga el modelo FastText previamente entrenado.\n",
    "\n",
    "- **Función de Conversión a Secuencias de Embeddings**: La función definida convierte una lista de ingredientes en una secuencia de embeddings:\n",
    "  - Se obtienen los embeddings para cada ingrediente si existe en el modelo.\n",
    "  - Si la receta tiene menos de `max_len` ingredientes, se añaden vectores de ceros hasta completar la longitud deseada.\n",
    "  - Si la receta tiene más de `max_len` ingredientes, se recorta la lista para que sólo los primeros `max_len` ingredientes se incluyan.\n",
    "  - La función devuelve una matriz numpy con la secuencia de embeddings.\n",
    "\n",
    "- **Generación de Secuencias de Embeddings para el Conjunto de Entrenamiento**: Se utiliza la función de conversión para transformar todas las recetas en el conjunto de entrenamiento en secuencias de embeddings, asegurando que los datos de entrada al modelo de deep learning estén preparados y estandarizados.\n",
    "\n",
    "Este enfoque permite representar cada receta de una manera que la red neuronal pueda procesar eficazmente, facilitando la tarea de clasificación de recetas basada en sus ingredientes.\n",
    "\n",
    "Además, es importante recalcar que es uno de los parametros que más se puede modificar y que podría alterar los resultados también, por lo que se realizarán pruebas posteriores para encontrar el mejor valor de `max_len`, buscando cual es el que mejor se ajusta a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convertir las etiquetas de cocina a valores numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(train_df['cuisine'])\n",
    "y_train = to_categorical(y_train_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
    "\n",
    "# Definir los hiperparámetros\n",
    "embedding_dim = 100  # Dimensionalidad de los embeddings que has usado con FastText\n",
    "max_len = 14         # Longitud de la secuencia (igual a lo que definiste antes)\n",
    "num_classes = y_train.shape[1]  # Número de clases, basado en la codificación one-hot de las etiquetas\n",
    "\n",
    "# Construir el modelo RNN\n",
    "model = Sequential([\n",
    "    Masking(mask_value=0.0, input_shape=(max_len, embedding_dim)),  # Ignora los ceros de relleno\n",
    "    LSTM(128, return_sequences=False),  # Cambia a GRU si prefieres, y ajusta la cantidad de unidades\n",
    "    Dropout(0.5),                       # Dropout para evitar overfitting\n",
    "    Dense(64, activation='relu'),       # Capa densa intermedia\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  # Capa de salida con softmax para clasificación multiclas\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de una Red Neuronal Recurrente (RNN) para Clasificación de Recetas\n",
    "\n",
    "Para este problema de clasificación de recetas basado en ingredientes, se ha optado por utilizar una Red Neuronal Recurrente (RNN). Las RNN son adecuadas para este tipo de problemas porque están diseñadas para trabajar con datos secuenciales, como texto o series temporales. En este caso, las secuencias de ingredientes pueden ser vistas como datos secuenciales donde el orden de los ingredientes y su contexto importan para la clasificación.\n",
    "\n",
    "**Justificación del Uso de una RNN**:\n",
    "- **Manejo de Secuencias**: Las RNN son excelentes para procesar secuencias de datos debido a su capacidad para mantener información contextual a través del tiempo.\n",
    "- **Contexto de Ingredientes**: En una receta, el orden y combinación de ingredientes pueden ofrecer pistas significativas sobre el origen del platillo. Las RNN pueden capturar estas dependencias temporales y contextuales.\n",
    "\n",
    "**Hiperparámetros del Modelo**:\n",
    "- **`embedding_dim=100`**: Esta es la dimensionalidad de los embeddings que se usaron con FastText. Se ha mantenido esta misma dimensionalidad en la RNN para asegurar consistencia en la representación de los ingredientes.\n",
    "- **`max_len=20`**: Se define la longitud de la secuencia como 20. Este valor se ha ajustado considerando la longitud promedio de ingredientes en las recetas, para asegurar que se capturen suficientes ingredientes sin añadir demasiados ceros de relleno.\n",
    "- **`num_classes=y_train.shape[1]`**: Este valor define el número de clases, basado en la codificación one-hot de las etiquetas. Es importante que el modelo tenga el mismo número de salidas que clases en el problema de clasificación.\n",
    "\n",
    "**Componentes del Modelo**:\n",
    "- **`Masking(mask_value=0.0, input_shape=(max_len, embedding_dim))`**: Se utiliza una capa de `Masking` para ignorar los ceros de relleno en las secuencias, evitando que estos afecten el entrenamiento del modelo.\n",
    "- **`LSTM(128, return_sequences=False)`**: Se elige una capa LSTM con 128 unidades. Las LSTM son un tipo de RNN que maneja mejor las dependencias a largo plazo. El número de unidades se ha seleccionado para equilibrar entre capacidad de aprendizaje y complejidad del modelo.\n",
    "- **`Dropout(0.5)`**: Se añade una capa de Dropout con una tasa del 50% para reducir el riesgo de sobreajuste. El Dropout apaga aleatoriamente la mitad de las neuronas durante el entrenamiento, lo que mejora la generalización del modelo.\n",
    "- **`Dense(64, activation='relu')`**: Una capa densa con 64 neuronas y activación ReLU se utiliza como capa intermedia para capturar relaciones no lineales entre los embeddings de los ingredientes.\n",
    "- **`Dense(num_classes, activation='softmax')`**: La capa de salida es una capa densa con activación softmax, que produce una probabilidad para cada una de las clases. Esto es adecuado para problemas de clasificación multiclas.\n",
    "\n",
    "**Compilación del Modelo**:\n",
    "- **`optimizer='adam'`**: Se utiliza el optimizador Adam, conocido por su eficacia y capacidad de adaptación durante el entrenamiento.\n",
    "- **`loss='categorical_crossentropy'`**: La función de pérdida es la entropía cruzada categórica, que es adecuada para problemas de clasificación con múltiples clases.\n",
    "- **`metrics=['accuracy']`**: Se ha especificado la precisión como métrica para evaluar el rendimiento del modelo durante el entrenamiento y la validación.\n",
    "\n",
    "Como se ha mencionado ya con anterioridad, se busca que el modelo sea capaz de clasificar recetas con la más alta precisión, por lo que se realizarán pruebas posteriores con diferentes configuraciones de hiperparámetros y cambios en la arquitectura del modelo para buscar optimizar su rendimiento. A pesar de justificar arriba por qué se eligieron estos hiperparámetros, aquí comparto otras ideas con las que se experimentará y se determinará posteriormente cual da mejores resultados.\n",
    "\n",
    "**Hiperparámetros a Experimentar**:\n",
    "1. **Unidades LSTM**: Probar con diferentes cantidades de unidades LSTM, como 64 o 256, para ver cómo afecta la capacidad del modelo para aprender las relaciones entre ingredientes.\n",
    "2. **Tasa de Dropout**: Ajustar la tasa de Dropout a valores como 0.3 o 0.7 para observar su impacto en la regularización y capacidad del modelo para generalizar.\n",
    "3. **Optimizador**: Experimentar con otros optimizadores, como RMSprop o SGD, para determinar si pueden ofrecer mejores resultados en términos de convergencia y precisión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.4841 - loss: 1.8364 - val_accuracy: 0.6449 - val_loss: 1.1489\n",
      "Epoch 2/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.6339 - loss: 1.2254 - val_accuracy: 0.6752 - val_loss: 1.0385\n",
      "Epoch 3/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.6601 - loss: 1.1440 - val_accuracy: 0.6878 - val_loss: 0.9985\n",
      "Epoch 4/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.6776 - loss: 1.0889 - val_accuracy: 0.6963 - val_loss: 0.9839\n",
      "Epoch 5/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.6838 - loss: 1.0611 - val_accuracy: 0.7082 - val_loss: 0.9523\n",
      "Epoch 6/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.6989 - loss: 1.0218 - val_accuracy: 0.7073 - val_loss: 0.9451\n",
      "Epoch 7/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 19ms/step - accuracy: 0.7091 - loss: 0.9962 - val_accuracy: 0.7216 - val_loss: 0.9232\n",
      "Epoch 8/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7135 - loss: 0.9612 - val_accuracy: 0.7176 - val_loss: 0.9251\n",
      "Epoch 9/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.7229 - loss: 0.9482 - val_accuracy: 0.7208 - val_loss: 0.8976\n",
      "Epoch 10/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7206 - loss: 0.9418 - val_accuracy: 0.7247 - val_loss: 0.9007\n",
      "Epoch 11/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7265 - loss: 0.9111 - val_accuracy: 0.7244 - val_loss: 0.8953\n",
      "Epoch 12/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7389 - loss: 0.8889 - val_accuracy: 0.7244 - val_loss: 0.9028\n",
      "Epoch 13/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7351 - loss: 0.8781 - val_accuracy: 0.7242 - val_loss: 0.9104\n",
      "Epoch 14/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.7423 - loss: 0.8620 - val_accuracy: 0.7231 - val_loss: 0.8973\n",
      "Epoch 15/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.7452 - loss: 0.8506 - val_accuracy: 0.7337 - val_loss: 0.8843\n",
      "Epoch 16/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.7520 - loss: 0.8348 - val_accuracy: 0.7299 - val_loss: 0.8966\n",
      "Epoch 17/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7539 - loss: 0.8224 - val_accuracy: 0.7277 - val_loss: 0.9012\n",
      "Epoch 18/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7573 - loss: 0.8056 - val_accuracy: 0.7318 - val_loss: 0.9185\n",
      "Epoch 19/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7634 - loss: 0.7869 - val_accuracy: 0.7319 - val_loss: 0.9102\n",
      "Epoch 20/20\n",
      "\u001b[1m796/796\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7717 - loss: 0.7575 - val_accuracy: 0.7382 - val_loss: 0.9059\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8083 - loss: 0.6070\n",
      "Training Accuracy: 0.7978\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print(f\"Training Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
      "Accuracy: 0.74\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.46      0.44      0.45        84\n",
      "     british       0.30      0.22      0.25       157\n",
      "cajun_creole       0.77      0.69      0.73       328\n",
      "     chinese       0.74      0.85      0.79       510\n",
      "    filipino       0.56      0.49      0.52       136\n",
      "      french       0.48      0.65      0.55       550\n",
      "       greek       0.71      0.60      0.65       249\n",
      "      indian       0.88      0.87      0.88       602\n",
      "       irish       0.48      0.30      0.37       151\n",
      "     italian       0.82      0.84      0.83      1567\n",
      "    jamaican       0.70      0.48      0.57        91\n",
      "    japanese       0.78      0.66      0.72       284\n",
      "      korean       0.71      0.65      0.68       166\n",
      "     mexican       0.90      0.92      0.91      1336\n",
      "    moroccan       0.73      0.71      0.72       166\n",
      "     russian       0.56      0.22      0.32        89\n",
      " southern_us       0.66      0.75      0.70       848\n",
      "     spanish       0.52      0.35      0.42       182\n",
      "        thai       0.75      0.75      0.75       315\n",
      "  vietnamese       0.59      0.40      0.48       144\n",
      "\n",
      "    accuracy                           0.74      7955\n",
      "   macro avg       0.66      0.59      0.61      7955\n",
      "weighted avg       0.74      0.74      0.74      7955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Generar secuencias de embeddings para todas las recetas en el conjunto de prueba (test_df)\n",
    "X_test = np.array([get_embedding_sequence(recipe, fasttext_model) for recipe in test_df['ingredients']])\n",
    "\n",
    "# Realizar las predicciones sobre el conjunto de prueba\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convertir las predicciones en las clases de cocina (índices a etiquetas)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Obtener las categorías de cocina del modelo de entrenamiento\n",
    "cuisine_labels = train_df['cuisine'].cat.categories\n",
    "\n",
    "# Mapear los índices de las predicciones a las etiquetas de cocina\n",
    "predicted_cuisines = cuisine_labels[predicted_labels]\n",
    "\n",
    "# Comparar con las etiquetas reales en test_df\n",
    "true_cuisines = test_df['cuisine']\n",
    "\n",
    "# Calcular la exactitud (accuracy)\n",
    "accuracy = accuracy_score(true_cuisines, predicted_cuisines)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Generar un reporte de clasificación con precisión, recall y F1-score\n",
    "report = classification_report(true_cuisines, predicted_cuisines)\n",
    "print('Classification Report:')\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de los primeros 20 resultados\n",
    "\n",
    "| Index  | True Cuisine   | Predicted Cuisine |\n",
    "|--------|-----------------|-------------------|\n",
    "| 21513  | chinese        | chinese           |\n",
    "| 1796   | spanish        | spanish           |\n",
    "| 21861  | greek          | greek             |\n",
    "| 26571  | indian         | indian            |\n",
    "| 28720  | italian        | italian           |\n",
    "| 39404  | mexican        | mexican           |\n",
    "| 29512  | italian        | italian           |\n",
    "| 5726   | cajun_creole   | southern_us       |\n",
    "| 35755  | greek          | greek             |\n",
    "| 35346  | mexican        | mexican           |\n",
    "| 27662  | cajun_creole   | southern_us       |\n",
    "| 37335  | spanish        | southern_us       |\n",
    "| 2116   | southern_us    | italian           |\n",
    "| 8409   | chinese        | chinese           |\n",
    "| 7672   | greek          | french            |\n",
    "| 17060  | mexican        | mexican           |\n",
    "| 6053   | indian         | southern_us       |\n",
    "| 25959  | filipino       | chinese           |\n",
    "| 7989   | mexican        | mexican           |\n",
    "| 38987  | italian        | italian           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados y Evaluación del Primer Modelo de Clasificación de Recetas\n",
    "\n",
    "**Training Accuracy**: 0.7978\n",
    "\n",
    "**Test Accuracy**: 0.74\n",
    "\n",
    "**Interpretación de Resultados**:\n",
    "El modelo de clasificación de recetas alcanzó una precisión de entrenamiento del 79.78%, lo que indica un buen ajuste durante el entrenamiento. Sin embargo, la precisión en el conjunto de prueba es del 74%, lo cual sugiere que el modelo podría beneficiarse de mayor refinamiento y ajustes de hiperparámetros para mejorar su capacidad de generalización.\n",
    "\n",
    "**Reporte de Clasificación**:\n",
    "El reporte de clasificación proporciona detalles sobre la precisión, recall y F1-score para cada una de las clases (tipos de cocina). Algunas observaciones claves incluyen:\n",
    "\n",
    "- **Cocina Brasileña**: Tiene una precisión y recall relativamente bajos, lo que indica que el modelo tiene dificultades para identificar correctamente las recetas brasileñas.\n",
    "- **Cocina Italiana y Mexicana**: Muestran altas precisiones y F1-scores, indicando que el modelo es capaz de clasificar estas cocinas de manera efectiva.\n",
    "- **Cocina Británica y Rusa**: Muestran resultados más bajos en todas las métricas, sugiriendo que el modelo tiene dificultades con estas categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo en disco\n",
    "model.save(\"rnn_cuisine_classifier_v1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejora del modelo \n",
    "\n",
    "Como se mencionó anteriormente, se realizarán pruebas posteriores con diferentes configuraciones de hiperparámetros y cambios en la arquitectura del modelo para buscar optimizar su rendimiento. A pesar de justificar arriba por qué se eligieron estos hiperparámetros, aquí comparto otras ideas con las que se experimentará y se determinará posteriormente cual da mejores resultados. \n",
    "\n",
    "**Hiperparámetros a Experimentar**:\n",
    "- max_len = [11, 14] \n",
    "- LSTM = [64, 128] \n",
    "- Dropout = [0.3, 0.5] \n",
    "- optimizer = ['adam', 'sgd']\n",
    "\n",
    "Para realizar lo anterior se aplicará la técnica de GridSearchCV, la cual permite probar diferentes combinaciones de hiperparámetros y seleccionar la mejor configuración para el modelo. Aquí a continuación se muestra como es que se modificó el modelo para poder realizar esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las etiquetas de train y test en formato one-hot\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(train_df['cuisine'].cat.codes, num_classes=num_classes)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(test_df['cuisine'].cat.codes, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'dropout_rate': 0.3, 'lstm_units': 64, 'max_len': 11, 'optimizer': 'adam'} => Accuracy: 0.7317\n",
      "Parameters: {'dropout_rate': 0.3, 'lstm_units': 64, 'max_len': 11, 'optimizer': 'sgd'} => Accuracy: 0.6755\n",
      "Parameters: {'dropout_rate': 0.3, 'lstm_units': 64, 'max_len': 14, 'optimizer': 'adam'} => Accuracy: 0.7443\n",
      "Parameters: {'dropout_rate': 0.3, 'lstm_units': 64, 'max_len': 14, 'optimizer': 'sgd'} => Accuracy: 0.6885\n",
      "Parameters: {'dropout_rate': 0.3, 'lstm_units': 128, 'max_len': 11, 'optimizer': 'adam'} => Accuracy: 0.7327\n",
      "Parameters: {'dropout_rate': 0.3, 'lstm_units': 128, 'max_len': 11, 'optimizer': 'sgd'} => Accuracy: 0.6850\n",
      "Parameters: {'dropout_rate': 0.3, 'lstm_units': 128, 'max_len': 14, 'optimizer': 'adam'} => Accuracy: 0.7393\n",
      "Parameters: {'dropout_rate': 0.3, 'lstm_units': 128, 'max_len': 14, 'optimizer': 'sgd'} => Accuracy: 0.6950\n",
      "Parameters: {'dropout_rate': 0.5, 'lstm_units': 64, 'max_len': 11, 'optimizer': 'adam'} => Accuracy: 0.7198\n",
      "Parameters: {'dropout_rate': 0.5, 'lstm_units': 64, 'max_len': 11, 'optimizer': 'sgd'} => Accuracy: 0.6607\n",
      "Parameters: {'dropout_rate': 0.5, 'lstm_units': 64, 'max_len': 14, 'optimizer': 'adam'} => Accuracy: 0.7286\n",
      "Parameters: {'dropout_rate': 0.5, 'lstm_units': 64, 'max_len': 14, 'optimizer': 'sgd'} => Accuracy: 0.6735\n",
      "Parameters: {'dropout_rate': 0.5, 'lstm_units': 128, 'max_len': 11, 'optimizer': 'adam'} => Accuracy: 0.7270\n",
      "Parameters: {'dropout_rate': 0.5, 'lstm_units': 128, 'max_len': 11, 'optimizer': 'sgd'} => Accuracy: 0.6686\n",
      "Parameters: {'dropout_rate': 0.5, 'lstm_units': 128, 'max_len': 14, 'optimizer': 'adam'} => Accuracy: 0.7378\n",
      "Parameters: {'dropout_rate': 0.5, 'lstm_units': 128, 'max_len': 14, 'optimizer': 'sgd'} => Accuracy: 0.6771\n",
      "Best Accuracy: 0.7443 with parameters: {'dropout_rate': 0.3, 'lstm_units': 64, 'max_len': 14, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import numpy as np\n",
    "\n",
    "# Definir los hiperparámetros a probar\n",
    "param_grid = {\n",
    "    'max_len': [11, 14],\n",
    "    'lstm_units': [64, 128],\n",
    "    'dropout_rate': [0.3, 0.5],\n",
    "    'optimizer': ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "# Crear una función para construir el modelo con los hiperparámetros dados\n",
    "def create_model(max_len, lstm_units, dropout_rate, optimizer):\n",
    "    model = Sequential([\n",
    "        Masking(mask_value=0.0, input_shape=(max_len, embedding_dim)),\n",
    "        LSTM(lstm_units, return_sequences=False),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam()\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD()\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Preparar los datos de entrenamiento y prueba con las diferentes longitudes de secuencia\n",
    "def preprocess_data(max_len):\n",
    "    X_train_processed = np.array([get_embedding_sequence(recipe, fasttext_model, max_len=max_len) for recipe in train_df['ingredients']])\n",
    "    X_test_processed = np.array([get_embedding_sequence(recipe, fasttext_model, max_len=max_len) for recipe in test_df['ingredients']])\n",
    "    return X_train_processed, X_test_processed\n",
    "\n",
    "# Convertir las etiquetas de train y test en formato one-hot\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(train_df['cuisine'].cat.codes, num_classes=num_classes)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(test_df['cuisine'].cat.codes, num_classes=num_classes)\n",
    "\n",
    "# Realizar la búsqueda en cuadrícula\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    max_len = params['max_len']\n",
    "    lstm_units = params['lstm_units']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    optimizer = params['optimizer']\n",
    "    \n",
    "    X_train_processed, X_test_processed = preprocess_data(max_len)\n",
    "    \n",
    "    model = create_model(max_len, lstm_units, dropout_rate, optimizer)\n",
    "    history = model.fit(X_train_processed, y_train_one_hot, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    \n",
    "    loss, accuracy = model.evaluate(X_test_processed, y_test_one_hot, verbose=0)\n",
    "    print(f\"Parameters: {params} => Accuracy: {accuracy:.4f}\")\n",
    "    results.append((params, accuracy))\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f} with parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación de los Resultados del Modelo\n",
    "\n",
    "El proceso de ajuste y evaluación del modelo utilizando diferentes configuraciones de hiperparámetros ha revelado importantes insights sobre el desempeño del modelo de clasificación de recetas. Los resultados obtenidos demuestran variaciones en la precisión del modelo dependiendo de los valores de los hiperparámetros probados.\n",
    "\n",
    "**Comparación de Hiperparámetros y Métricas de Evaluación**:\n",
    "1. **Max Len**:\n",
    "   - Las longitudes de secuencia probadas fueron 11 y 14. Se observó que una longitud de secuencia de 14 proporcionó mejores resultados en comparación con una longitud de 11, lo cual es coherente con la necesidad de capturar suficiente información contextual de los ingredientes.\n",
    "2. **Unidades LSTM**:\n",
    "   - Se probaron 64 y 128 unidades LSTM. Las configuraciones con 64 unidades LSTM mostraron un rendimiento competitivo con configuraciones de 128 unidades, pero con menor complejidad computacional.\n",
    "3. **Dropout Rate**:\n",
    "   - Las tasas de dropout de 0.3 y 0.5 fueron comparadas. Se encontró que una tasa de dropout de 0.3 ofreció mejores resultados en la mayoría de los casos, posiblemente debido a un balance más efectivo entre regularización y retención de información útil.\n",
    "4. **Optimizador**:\n",
    "   - Se probaron los optimizadores Adam y SGD. Adam consistentemente superó a SGD en términos de precisión, lo cual es esperado debido a la capacidad adaptativa de Adam para ajustar las tasas de aprendizaje.\n",
    "\n",
    "**Resultados Finales**:\n",
    "El mejor desempeño del modelo se obtuvo con la siguiente configuración de hiperparámetros:\n",
    "- **max_len**: 14\n",
    "- **lstm_units**: 64\n",
    "- **dropout_rate**: 0.3\n",
    "- **optimizer**: Adam\n",
    "\n",
    "Esta configuración alcanzó una precisión de **0.7443**, mostrando su efectividad en la clasificación de recetas basadas en ingredientes.\n",
    "\n",
    "### Elección de los Parámetros Óptimos\n",
    "\n",
    "La selección de los parámetros óptimos se basó en un cuidadoso análisis de los resultados de las pruebas. La longitud de secuencia de 14 fue elegida porque capturó una cantidad suficiente de información contextual sobre los ingredientes sin introducir demasiado ruido de ingredientes irrelevantes. Esta longitud equilibrada permitió al modelo aprender de manera efectiva las relaciones entre los ingredientes, hay muchos platillos que se quedan con ingredientes sin capturar debido a tener 11 de máximo, número que reduce bastante a comparación de con 14.\n",
    "\n",
    "El número de unidades LSTM se estableció en 64, lo cual resultó ser suficiente para modelar las secuencias de ingredientes sin añadir una complejidad innecesaria al modelo. Esta elección ayudó a mejorar la eficiencia computacional y reducir el tiempo de entrenamiento sin sacrificar la precisión.\n",
    "\n",
    "La tasa de dropout de 0.3 proporcionó el mejor balance entre regularización y retención de información, permitiendo al modelo generalizar bien sin sobreajustarse a los datos de entrenamiento. Esto es crucial para asegurar que el modelo funcione bien en datos no vistos.\n",
    "\n",
    "El optimizador Adam fue seleccionado debido a su capacidad adaptativa y eficiencia en la convergencia del modelo, lo que permitió alcanzar una precisión más alta en comparación con SGD. Adam ajusta dinámicamente las tasas de aprendizaje, lo cual es especialmente útil para modelos complejos y grandes volúmenes de datos, que considerando la cantidad de ingredientes únicos que existían considero que en eso se vio mucho más beneficiado a comparación del SDG.\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "**Conclusión Técnica**:\n",
    "Los parámetros \"ganadores\" fueron seleccionados debido a su impacto positivo en el rendimiento del modelo. La longitud de secuencia de 14 permite capturar suficientes ingredientes para una representación robusta. Un menor número de unidades LSTM (64) ofrece un buen equilibrio entre rendimiento y eficiencia computacional. La tasa de dropout de 0.3 ayuda a regularizar el modelo sin perder demasiada información. Finalmente, el optimizador Adam proporciona una convergencia rápida y eficiente.\n",
    "\n",
    "**Conclusión del Proyecto**:\n",
    "Lo que más me gustó del proyecto fue la aplicación práctica del deep learning para resolver un problema real de clasificación de recetas, demostrando cómo la tecnología puede transformar datos complejos en información valiosa. Aprendí mucho sobre el ajuste de hiperparámetros y la importancia de probar diferentes configuraciones para optimizar el rendimiento del modelo. Los mayores retos fueron manejar la variabilidad de los datos de ingredientes y asegurarse de que el modelo no se sobreajustara. Estos retos fueron superados mediante una cuidadosa selección de hiperparámetros y el uso de técnicas de regularización como el dropout.\n",
    "\n",
    "Este proyecto no solo enriqueció mi comprensión de las RNN y su aplicación, sino que también me proporcionó una experiencia invaluable en la práctica de machine learning y el ajuste de modelos.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
